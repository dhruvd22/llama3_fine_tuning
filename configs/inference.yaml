# Base model location (local path or HF repo)
model:
  # Path to the Llama 3.1 8B base model. Change if you downloaded it locally.
  base_model_path: "/workspace/data/mygitstuff/llama3_fine_tuning/models/base_3_1_8b/"
  adapters: []  # List of adapter paths (optional)

# Path to the JSON prompt template used for inference
prompt_template: configs/prompt_templates/inference_prompt_temp_default.json

# Optional stop sequences to truncate the response when encountered
stop:
  - "```"
  - ";\n"

